[{"authors":null,"categories":null,"content":"I use methods from econometrics and machine learning, insights from behavioural science, and large datasets to study human behaviour in the wild. The scientist in me loves doing this to further understanding; the craftsman in me, to help build great products.\n  Download my CV.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I use methods from econometrics and machine learning, insights from behavioural science, and large datasets to study human behaviour in the wild.","tags":null,"title":"Fabian Gunzinger","type":"authors"},{"authors":[],"categories":[],"content":"","date":1650787369,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650787369,"objectID":"063af6de2357f6049ea2abc1399a49fc","permalink":"https://fabiangunzinger.github.io/post/analysis-checklist/","publishdate":"2022-04-24T09:02:49+01:00","relpermalink":"/post/analysis-checklist/","section":"post","summary":"","tags":[],"title":"Analysis Checklist","type":"post"},{"authors":null,"categories":null,"content":"  ","date":1646006400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646006400,"objectID":"32ba20c8da2a3d95f8916b456b4199ae","permalink":"https://fabiangunzinger.github.io/post/python-dictionaries/","publishdate":"2022-02-28T00:00:00Z","relpermalink":"/post/python-dictionaries/","section":"post","summary":"  ","tags":["python"],"title":"Python dictionaries","type":"post"},{"authors":null,"categories":null,"content":"  ","date":1645747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645747200,"objectID":"3a3855edffd2caf2158357c3201a7436","permalink":"https://fabiangunzinger.github.io/post/heaps/","publishdate":"2022-02-25T00:00:00Z","relpermalink":"/post/heaps/","section":"post","summary":"  ","tags":["python"],"title":"Heaps","type":"post"},{"authors":null,"categories":null,"content":"My evolving notes and on how to effectively use Git and GitHub.\nGit   Evolution of version control systems (and their shortcomings): from having differently named files and folders (error prone and inefficient) to local version control systems (LVCs) where files are checked out from a locally hosted database that contains the entire history (single point of failure and impractical for collaboration) to centralized version control systems (CVCSs) where files are checked out from a server-hosted database (single point of failure) to distributed version control systems (DVCs) where files and a database containing the entire history are checked out from a served-hosted database, so that each local node contains all information stored on the server (content on server can easily be restored in case of failure).\n  Git stores data as snapshots: at each new commit, modified files are replaced with a snapshot of their new state, while unmodified files are replaced with a link to the previous snapshot.\n  In a basic workflow I edit a file in the working tree (the locally checked out version of the project), add them to the staging area (also called index), commit them to the local database, and finally push them to the remote database on GitHub.\n  Neither main (or, formerly, master), nor origin have any special significance in Git. The reason they are widely used is that main is the default name for the starting branch when running git init and origin is the default name for the remote repository when running git clone.\n  Git stores a single file as a blob, which is a backronym for binary large object and is a collection of binary data. It can store any type of data including multimedia files and images. Blobs in the git object database are stored named with a SHA-1 hash key of their content and containing the exact same content as the file would on my filesystem.\n  Interacting with remotes   A remote repository is a version of the project that’s hosted on a server, in my case always on GitHub. The default name Git assigns to the remote when I clone it is origin. (Technically, the remote could also be hosted on my machine but in a separate location from my working copy.)\n  git fetch \u0026lt;remote\u0026gt; downloads all new objects from the remote repository (e.g. including references to new branches) but does not automatically merge these objects into my local work. git pull fetches and automatically merges the remote version of the local branch I’m currently on and merges it if the current branch is set up to track the remote. By default, git clone sets up my local main branch to track the remote version, named origin/main.\n  To share work with the remote, I can use git push \u0026lt;remote\u0026gt; \u0026lt;branch\u0026gt; (e.g. to share work from my local main branch with origin/main, I can do git push origin main).\n  Undoing things   Cardinal rule: don’t push stuff before you’re fully happy with it. Changing your local history is easy, changing the history on the server isn’t.\n  Changing message of last commit: (with an empty index) run git commit --amend.\n  Changing the content of the last commit: stage changes you want to add, then run git commit --amend. If you don’t want to change the commit message, append --no-edit.\n  Unstaging a staged file: git restore --staged \u0026lt;pathspec\u0026gt;.\n  Undoing changes in the working directory and reverting a file to its state after the last commit: git restore \u0026lt;pathspec\u0026gt;.\n  Changing multiple commits (edit, reorder, squash, delete, split, etc.): git rebase -i HEAD~#, where # is the parent of the last commit you want to edit (e.g. if you want to edit the last 3 commits, HEAD~3 will select commits HEAD, HEAD~1, and HEAD~2). More in docs\n  I’ve accidentally overwritten a file with content I meant to place in a new file, and now want to 1) save the new content under a different name and 2) restore the file I’ve overwritten. Solution: Just save the new content under a new name (temporarily deleting the file I’ve accidentally overwritten, and then use git restore \u0026lt;name_of_overwritten_file\u0026gt; to restore the old version of the overwritten file.\n  I’ve deleted one or more commits (e.g. by using a hard reset) that I need to recover. First thing to try: run git reflog to get a log of commits HEAD pointed to. Once I’ve identified the commit I need (ab1af) I can create a new branch that points to it using git branch recover-branch ab1af. If there is no reflog, I can run git fsck --full to check the database for integrity and get a list of objects that aren’t reacheable. The commit I’m looking for will be labelled with dangling commit, and I can create a branch pointing to it.\n  Removing a file from every commit (e.g. accidentally committed large data file): git filter-branch --index-filter \u0026#39;rm --ignore-unmatch --cached data.csv\u0026#39; HEAD. This can take a long time. One way to speed things up is to find the commit that added the file to the history and only filter downstream from there. git log --oneline --branches -- data.csv will list all commits …","date":1643760000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643760000,"objectID":"a64b1b7c7f27ecc7e81c833938a437c9","permalink":"https://fabiangunzinger.github.io/post/git/","publishdate":"2022-02-02T00:00:00Z","relpermalink":"/post/git/","section":"post","summary":" ","tags":["tools"],"title":"Git","type":"post"},{"authors":null,"categories":null,"content":"  ","date":1642809600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642809600,"objectID":"c5d1093e959acf95188f893c6e5c5936","permalink":"https://fabiangunzinger.github.io/post/iterators-and-generators/","publishdate":"2022-01-22T00:00:00Z","relpermalink":"/post/iterators-and-generators/","section":"post","summary":"  ","tags":["python"],"title":"Iterators and generators","type":"post"},{"authors":null,"categories":null,"content":"  ","date":1641686400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641686400,"objectID":"6a6d2d4495e5008e7a876743a24461a3","permalink":"https://fabiangunzinger.github.io/post/entropy/","publishdate":"2022-01-09T00:00:00Z","relpermalink":"/post/entropy/","section":"post","summary":"  ","tags":["stats"],"title":"Entropy","type":"post"},{"authors":null,"categories":null,"content":"  The goal of algorithm analysis is to study the efficiency of an algorithm in a language and machine-independent way.\n  The two most important tools for this are (1) the RAM model of computation and (2) the asymptotic analysis of worst-case complexity.\n  The Random Access Machine (RAM) model of computation is a simple model of a generic computer that is based on three main assumptions: (1) each simple operation takes exactly one time step, (2) loops and subroutines are considered composites of all simple operations they perform, and (3) memory access from cache and RAM takes one time unit. None of these hold in practice, but the model is extremely useful because it captures the essence of algorithm behaviour while being very simple to work with.\n  Best, worst, and average-case complexity are functions defined by the minimum, maximum, and average number of steps taken for any instance of size n of the input string. (Think about a graph with n on the x-axis and number of steps on the y-axis, with number of steps for each instance of a problem of size n forming columns of dots with increasing variation as n – and thus the number of possible instances – increases. The three functions trace the lowest, highest, and middle dots at each input size n. See Fig 2.1 in ADM.)\n  Using these functions to analyse algorithms is impractical, however, because they are not smooth and require lots of detail about the algorithm and its implementation.\n  Big O notation ignores such details and focuses on the essentials to capture the rate at which runtime (or space requirements) grow as a function of the input size (the letter O is used because the growth rate of a function is also called its order). In essence, this means only focusing on the higest order term and ignoring constants (which depend on things like hardware and programming language used to run the algorithm).\n  A function $f(n)$ is $O(g(n))$ if there exist constants $c$ and $n_0$ such that $f(n) \\leq cg(n)$ for any $n \u0026gt; n_0$. Intuitively, this means that $f(n)$ grows no faster than $cg(n)$ above a certain input size. For example: $T(n) = 2n^2 + 3n$ is $O(n^2)$, since $5n^2 \\geq 2n^2 + 3n$ for all positive values of $n$.\n  Amortised worse-case complexity takes into account that the running time of a given operation in an algorithm may take a very long or a very short time depending on the situation, and averages those different running times of the operation in a sequence over that sequence. Adding an element to an array that is dynamically resized takes $O(1)$ time until the array is full, when the array needs to create a new array of twice its original size, copy all elements over to the new array, and add the new element, which takes $O(n)$ time. Average worst-case complexity averages these runtimes to find that pushing elements onto a dynamically resized array takes: $\\frac{nO(1) + O(n)}{n + 1} = O(1)$, constant time. (Source)\n  Exercises:\n  Is $2^{n+1} = O(2^n)$?\n  Is $(x + y)^2 = O(x^2 + y^2)$?\n  What’s the time complexity of $f(n) = min(n, 100)$?\n  Solutions:\n  The way to go is to start from the definition. The statement is true if there is a $c$ and $n_0$ for which $c2^n \\geq 2^{n+1}$ for $n \u0026gt; n_0$. The key is to rewrite the right hand side to $c2^n \\geq 2 \\times 2^n$, which makes it obvious that the statement holds whenever $c \\geq 2$.\n  Starting from the definition, the statement is true if there exist constants $c$ and $n_0$ for which $c(x^2 + y^2) \\geq (x + y)^2$ for $n \u0026gt; n_0$. Expanding the right hand side, we get $c(x^2 + y^2) \\geq x^2 + 2xy + y^2$. Ignoring the middle term, the statement holds for $c = 1$; considering only the middle term, we see that it is largest when $x = y$, in which case the statement holds for $c = 2$. Thus, $3(x^2 + y^2) \\geq (x + y)^2$, so the statement is true.\n  I reflexively answered $n$. Thinking for a moment (an embarassingly long one, admittedly), I realised that $n$ here refers not to the length of an array but to a single number. So the operation is $O(1)$.\n  Sources   Steven Skiena, The Algorithm Design Manual (ADM)\n  MIT, Big O notation\n  Wikipedia, Big O notation\n  ","date":1637452800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637452800,"objectID":"71325568208e87e1442c6426dbe67970","permalink":"https://fabiangunzinger.github.io/post/algorithm-complexity-analysis/","publishdate":"2021-11-21T00:00:00Z","relpermalink":"/post/algorithm-complexity-analysis/","section":"post","summary":" ","tags":["cs"],"title":"Algorithm complexity analysis","type":"post"},{"authors":null,"categories":null,"content":"My regular expression cheatsheet, focused on the Python engine. A lot of content is heavily based on (and often shamelessly copied from) the amazing RexEgg and Regular-Expressions.info sites.\nBasics   A regex is a text string that a regex engine uses to find text or positions in a body of text, typically for the purposes of validating, finding, replacing, and splitting.\n  To differentiate between the string that makes up the regex and the string that is being searched, the former is often called regex or pattern and the latter string or subject.\n  A (lexical) token is a string with an assigned and thus identified meaning (more here). For instance, the token \\w in a pattern stands for a word-character, and will be replaced by that when the engine parses the string.\n  The Python regex engine (and all other modern engines) is regex-directed: it attempts all possible permutations of the regex at a character position of the subject before moving on to the next character (which can involve lots of backtracking). In contrast, text-directed engines visit each character in the subject text only once. This makes them faster but also less powerful.\n  A regex engine is eager: it scans alternatives in the regex from left to right and returns the first possible match – Jane|Janet would return Jane as a match in Janet is tall.\n  Characters   There are four types of characters: literal characters (e.g. a), metacharacters (^), non-printable characters (\\n), and shorthand character classes (\\w).\n  Literal characters simply match themselves: the single literal character a matches the first a in the string, the sequence of literal characters cat the first occurrence of cat.\n  Metacharacters are the twelve punctuation characters from the ACSII table that make regex work its magic: $, (, ), *, +, ., ?, [, \\, ^, {, |. To match metacharacters as literals, escape them with a backslash, as in 1\\+2=3. Exceptions are { and }, which are only treated as metacharacters when part of a quantifier, and ], which only takes on special meaning when part of a character class).\n  Non-printable characters or formation marks are characters used to tell word processors how text needs to look and do not appear in printed text.\n  Shorthand character classes are tokens for certain common character classes.\n  Non-printable characters\n   Character Legend     \\r Carriage return   \\n Newline   \\r\\n Line-break on Windows   \\t Tab   \\f Form-feed    Shorthand character classes\n   Character Legend     \\d Single digit, short for [0-9]   \\D Complement of \\d, short for [^\\d]   \\w Word character, short for [a-zA-Z\\_]   \\W Complement of \\w, short for [^\\w]   \\s Whitespace character, short for [\\r\\n\\t\\f\\v ]   \\S Complement of \\s, short for [^\\s]   \\v Vertical whitespace, short for [\\n\\f\\r]   \\V Complement of \\v    Character classes   Character classes tell the engine to match one of several characters.\n  Importantly: [^a-z]u does not mean “u not preceded by a lowercase letter”, but “u preceded by something that isn’t a lowercase letter”. Hence, the pattern doesn’t match a u at the beginning of a string. (In contrast to the ., the negated character class does match invisible line breaks, though, so the above pattern would match the string \\nu.)\n  Within a character class, metacharacters are literals with the exception of ^, -, \\ and ] if they are used in places where they have special meaning: ^ at the beginning, - as part of a range, ] at the end, and \\ to escape another special character or to form a token (i.e. always), and ] at the end. Hence, this regex matches them all as literals: []\\\\-^] (for details on how to includ metacharacters indide character classes without escaping them, see relevant section here here].\n  Character classes examples\n   Regex Match     [ab] One of a or b   [^ab] Any character that isn’t a or b (incl. newline)   [\\w\\s] One word or whitespace character   [A-By-z1-2] One of A, B, y, z, 1, 2   [ -~] Any character in the printable section of the ASCII   table     Exercises:\n  Match gray and grey in London is grey; New York, gray..\n  Match any character that is neither a digit nor a (hidden) line break character.\n  What does q[^u] match in Iraq and Iraq is a country?\n  How could we match any q not followed by a u?\n  Search for a literal * or +.\n  Match any number greater than 10 made up of all the same digit (e.g. 222, 33, 5555).\n  In b ab cb, match b either at the beginning of the string or when preceded by an a.\n  What’s the difference between [\\D\\S] and [^\\d\\s]?\n  Solutions:\n  \\bgr[ae]y\\b. Discussion: need global flag on or use findall() in Python to match both words, otherwise I’ll just get the first one.\n  [\\D\\V]. Discussion: the negated character classs matches hidden line break character by default (unlike the .), so need to explicitly exclude them.\n  Nothing and q . Discussion: the regex means “q followed by something that is not a u”, not “q not followed by a u”, so it requires something to follow the q, and that something to not be …","date":1636761600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1636761600,"objectID":"599655f2d892060746426d44f3585f1e","permalink":"https://fabiangunzinger.github.io/post/regex/","publishdate":"2021-11-13T00:00:00Z","relpermalink":"/post/regex/","section":"post","summary":" ","tags":["tools","cheatsheet"],"title":"Regex","type":"post"},{"authors":null,"categories":null,"content":"  ","date":1636588800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1636588800,"objectID":"3c9fa3ecb795072e195d8aa92c7f5980","permalink":"https://fabiangunzinger.github.io/post/pandas-categories/","publishdate":"2021-11-11T00:00:00Z","relpermalink":"/post/pandas-categories/","section":"post","summary":"  ","tags":["pandas"],"title":"Pandas categories","type":"post"},{"authors":null,"categories":null,"content":"  ","date":1632268800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632268800,"objectID":"d911e969d2de9db8d5f399b1fda033cd","permalink":"https://fabiangunzinger.github.io/post/python-string-formatting/","publishdate":"2021-09-22T00:00:00Z","relpermalink":"/post/python-string-formatting/","section":"post","summary":"  ","tags":["python"],"title":"Python string formatting","type":"post"},{"authors":null,"categories":null,"content":"  ","date":1631318400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1631318400,"objectID":"50ed92c5732c8c067dd3d1c607144077","permalink":"https://fabiangunzinger.github.io/post/python-regex/","publishdate":"2021-09-11T00:00:00Z","relpermalink":"/post/python-regex/","section":"post","summary":"  ","tags":["python"],"title":"Python regex","type":"post"},{"authors":null,"categories":null,"content":"Preliminaries   I use neovim. My configuration is here. There, I map \u0026lt;esc\u0026gt; to jk, a mapping I also use throughout this file.\n  I’ve remaped Caps Look to \u0026lt;ctrl\u0026gt; on my mac.\n  Reminders   Use one keystroke to move and one to execute (e.g. the dot-formula).\n  Exit and re-enter insert mode strategically to chunk your undos (all changes in a single insert session count as one change).\n  If you hit cursor keys more than 2 or 3 times, press backspace more than a couple times, perform the same change on several lines, there is a better way.\n  I want to open a file and get an E325: ATTENTION Found a swap file warning. What happened? For me, it’s most likely that I accidentally closed a terminal window while still editing the file. What to do? First, check that I’m not already editing the file elsewhere. Second, recover the file, save it under a new name (:w filename2), force quit the session, compare the original and the new file (diff filename filename2), use the file with the content I need and delete the other one and the swap file. (Based on this great SE answer.)\n  Don’t solve a problem unless you come across it frequently (and if you do, check whether one of Tim Pope’s plugins solves it).\n  Useful stuff I tend to forget:\n   Command Effect     \u0026lt;C-f\u0026gt;/\u0026lt;C-b\u0026gt; Scroll down/up screen-wise (“forwards-backwards”)   c-x c-e In command line: edit current line in vim, run after quit   :x Like :wq but only write if file was changed   set: {option}? Show present setting for {option}   set: {option}\u0026amp; Set option back to default value   | Command separator (equivalent to ; in shell)   \u0026lt;c-k\u0026gt;-N Enter en dash in insert mode using digraphs   \u0026lt;c-o-o\u0026gt; After opening vim, opens last file with cursor at last   edit     Help    Command Effect     gO Show table of contents for current help file   :helpc[lose] Close help windows if any are open   :vert h {keyword} Open help in a vertical split    Modes Normal mode  Operators work as follows: operator + motion = action. E.g. dl deletes character to the right, diw the word under the cursor (without the surrounding whitespace), dap the current paragraph (including the surrounding whitespace). Similarly, gUap converts the current paragraph to uppercase.  Common operators:\n   Trigger Effect     c Change   d Delete into register   y Yank into register   p Paste after cursor   P Paste before cursor   ~ Swap case of character under cursor and move right   gu Make lowercase   gU Make uppercase   g~ Swap case   \u0026gt; Shift right   \u0026lt; Shift left   = Autoindent   ! Filter {motion} lines through an external program    Moving back and forth:\n   Forwards Backwards Effect     / ? Seach for pattern   * # Search for word under cursor   n N Jump to next search match   $ ^ Jump to end of line   a{char} F{char} Position cursor on character   t{char} T{char} Position cursor before character   ; , Repeat the last r, F, t, or T   w b Move to the start of the next word   W B Move to the start of the next WORD   } { Move down one (blank-line-separated) paragraph   gg  Jump to the first line of the document   G  Jump to the last line of the document    Act, repeat, reverse:\n   Intent Act Repeat Reverse     Make a change {edit} . u   Scan line for next character f{char}/t{char} ; ,   Scan line for previous character F{char}/T{char} ; ,   Scan document for next match /pattern\u0026lt;CR\u0026gt; n N   Scan document for previous match ?pattern\u0026lt;CR\u0026gt; n N   Perform substitution :s/old/new \u0026amp; u   Execute a sequence of changes qx{change}q @x u    Compound commands:\n   Compound command Equivalent in longhand     C c$ (delete from cursor until end of line and start insert)   D d$ (delete from cursor until end of line)   Y y$ (similar to above, but has to be mapped, see h: Y)   s cl (delete single character and start insert)   S ^c (delete entire line and start inster, synonym for cc)   x dl (delete one character to the right)   X dh (delete one character to the left)   I ^i (jump to beginning of line and start insert)   A $a (jumpt to end of line and start insert)   o A\u0026lt;cr\u0026gt;   O ko    Miscellaneous:\n   Command Effect     \u0026lt;C-a\u0026gt;/ \u0026lt;C-x\u0026gt; Add / subtract from the next number   \u0026lt;C-o\u0026gt;/ \u0026lt;C-i\u0026gt; Move backwards to last / forward to previous location   u/\u0026lt;C-r\u0026gt; Undo / redo change   ga Reveal numeric representation of character under cursor   gx Open url under cursor   \u0026lt;C-z\u0026gt;/fg Put vim in background / return to vim    Insert mode Entering insert mode:\n   Trigger Effect     i Insert before cursor   a Insert after cursor   I Insert at beginning of current line   A Insert at end of current line   o Insert in a new line below the current one   O Insert in a new line above the current one   gi Insert at the end of last insert    Useful commands:\n   Keystroke action     \u0026lt;c-h\u0026gt; delete back one character (backspace)   \u0026lt;c-w\u0026gt; delete back one word   \u0026lt;c-u\u0026gt; delete back one line   \u0026lt;c-o\u0026gt; Enter insert normal mode to execute a single normal cmd   \u0026lt;C-r\u0026gt;{register} Paste content from address (use 0 for last yanked text)   \u0026lt;C-r\u0026gt;= Perform calculation in place   r, R Enter replace mode for …","date":1631318400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1631318400,"objectID":"25deb4ea7cf22877f3f1b7cbac7b8e24","permalink":"https://fabiangunzinger.github.io/post/vim/","publishdate":"2021-09-11T00:00:00Z","relpermalink":"/post/vim/","section":"post","summary":" ","tags":["tools","cheatsheet"],"title":"Vim","type":"post"},{"authors":null,"categories":null,"content":"  A makefile is a data base that tells the make utilit how to recompile a system. In the default use case, $: make \u0026lt;filename\u0026gt; checks whether filename is out of date and, if so, recompiles it. In the way I use makefiles, $: make \u0026lt;rule\u0026gt; executes a predefined rule to accomplish a certain task like cleaning a particular dataset.\n  Rules consist of a target (the name of a file to be modified), prerequisites (other files on which the target depends on), and commands to be run in order to update the traget based on changes in the prerequisites.\n  A rule tells make when a target is out of date and how to update it. A target is out of date if it doesn’t exist or is older then one of its prerequisite files.\n  $: make executes the first specified rule, $: make \u0026lt;rule\u0026gt; executes a particular rule.\n  A normal prerequisite makes both an order statement and a dependency statement: the order statement ensures that all commands needed to produce the prerequisete are fully executed before any commands to produce the target, while the dependency statement ensures that the target is updated every time a prerequisite changes. Occasionally, we want a prerequisite to invoke the order without the dependency statement (i.e. target is not udpated when the prerequisite changes, but when target is being updated, then the prerequisite commandas are run first). We can do this by writing the rule as target: normal-prerequisites | order-only-prerequisites.\n  make does its work in two phases: during the read-in phase, it reads the makefile and internalises variables and rules to construct a dependency graph of all targets and their prerequisies; during the target-update phase, it determines what rules to update in what order and executes the commandas to do so.\n  As a result, variable and function expansion can happen either immediately (during the read-in phase) or deferred (after the read-in phase), and gives rise to two flavours of variables: recursively expanded variables, defined by varname = value are expanded at the time the variable is substituted during the target-update phase. Before that point, varname contains the content of value verbatim (e.g. if value is $(othervar), then that last string is the value of varname). In contrast, simply expanded variables, defined by varname := value is expanded immediately when the variable is defined during the read-in phase (and varname would be bound to the value of othervar in the above example).\n  To define a variable containing all csv files in a directory, do csvs := $(wildcard *.csv). The wildcard function is needed here so that the wildcard gets expanded during function creation (as opposed to creating the variable with value *.csv). I could also create a list containing the same files but with a parquet extensions like so: `parqs := $(patsubst %.csv,%.parquet,$(wildcard *.csv)).\n  Automatic variables: $^ is a list of all prerequisites, $@ is the target, $\u0026lt; the first prerequisite.\n  If a target is an action to be performed rather than a file to be updated, then it’s called a phony target. In this case, telling make that we’re using a phone target explicitly by prepending the rule with a line like .PHONY : nameofrule is useful for two reasons: make doesn’t think of a file called nameofrule as the target (which, if it did, would mean that our rule never gets run because it has no prerequisites so that make would think of nameofrule as always up to date) and it doesn’t check for implicit commands to update the target, which improves performance.\n  Commands begin with a tab and, unless specified otherwise, are executed by bin/sh. You can set a different shell by changing the value of the SHELL variable (I usually use SHELL := /bin/bash. Each line that begines with a tab and appears within a rule context (anything between the start of one rule and another) is interpreted as a command and sent to the shell.\n  The only thing make does with commands is to check for \\ before newline, and for variables to expand (if you want $ to appear in the command, use $$). To prevent make from echoing a command, prepend it with @.\n  Prepend a command with - if you want make to continue regardless of errors. This can be useful for commands like -rm tempfile.csv, where you probaby want to continue even if the file didn’t exist and could thus not be removed.\n  Best practices Define a phony target:\n.PHONY: clean clean: rm *.csv  Make $: make run all rules:\n.PHONY: all all : rule1 rule2 .PHONY: rule1 rule1: mkdir hello .PHONY: rule2 rule2: rm -rf hello  ","date":1629676800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629676800,"objectID":"75f908b1f4a0c4ddba1293ed5b324a35","permalink":"https://fabiangunzinger.github.io/post/makefiles/","publishdate":"2021-08-23T00:00:00Z","relpermalink":"/post/makefiles/","section":"post","summary":" ","tags":["tools","cheatsheet"],"title":"Makefiles","type":"post"},{"authors":null,"categories":null,"content":" When people look under the hood, we want them to be impressed by the neatness, consistency, and attention to detail […] If instead they see a scrambled mass of code that looks like it was written by a bevy of drunken sailors, then they are likely to conclude that the same inattention to detail pervades every other aspect of the project. Robert Martin, Clean Code\n Definitions   A design pattern is a general repeatable solution to a frequently occuring problem.\n  An idiom is the translation of a design pattern into code using the language clearly and correctly.\n  Principles   Don’t repeat yourself. Collect often used pieces of code in a function of class for reuse. Don’t copy and paste more than once.\n  Single Responsibility Principle (SRP): a class or module should only have a single reason to change – it should be responsible to a single actor that can demand change. Example: an employee class that produces outputs for the finance and HR departments violates the principle, as both the CFO and the CHO might demand changes that then unintenionally affects the output seen by the other. Solution: Separate code that different actors depend on. Corollary: don’t reuse a function for two different outputs just because it does they require the same task, only reuse the function for two outputs that require the same task and have a common owner. Example, don’t if both HR and finance need to calculate regular hours, don’t use the same function, as the CFO might want to change the definition of regular hours but HR doesn’t.\n  Open-Closed Principle (OCP): classes should be open for extension and closed for modification. (We should easily be able to add new functionality without having to change existing functionality.)\n  Use names to make the context explicit (e.g. “for user in users” is explicit, “for i in list” isn’t).\n  Get to proof of concept asap.\n  “You ain’t gonna need it” (YAGNI). Don’t add functionality before it’s really necessary.\n  Names   Choose names that make clear what a thing is, what it does, and how it is used.\n  Use plain and unabbreviated words.\n  Omit needless words like “get” or “calculate”, but remember that “terseness and obscurity are the limits where brevity should stop”.\n  Use verbs or verb phrases for functions, nouns for classes.\n  Choose names of variables in proportion to their scope.\n  Whenever appropriate, use names from the solution domain (e.g. computer or data science) or the problem domain (e.g. personal finance) otherwise.\n  Functions   Functions should do one thing and one thing only and should do it well. (It’s not always obvious what “one thing” is, use your judgement.)\n  Make functions as short as possible to make it obvious how they work and what they are for.\n  Most often, blocks inside flow control statements should be one line long - calls to transparently named functions.\n  A good function interface allows the user to do what they need without having to worry about unnecessary details. Hence: ask for the minimally required number of intuitive arguments and return the expected output.\n  Write pure functions. A function is pure when it is idempotent (returns the same output for a given input) and has no side-effects.\n  Comments and docstrings   Don’t comment bad code – rewrite it.\n  Add docstrings to functions unless – following Google – they are helpers, short and obvious.\n  Modules  Use the module.function idiom (i.e. use import module rather than from module import function) in all but the simplest projects.  Systems   Kent Beck’s four rules for a simply designed system (in order or importance):\n  It runs all tests\n  Contains no duplication\n  Expresses the intent of the programmer (choose expressive names, keep functions and classes small, use standard nomenclature, good unit tests)\n  Minimises the number of classes and methods\n    Resources   Clean Code\n  The Hitchhiker’s Guide to Python, code style\n  IPython cookbook, writing high-quality Python code\n  Google style guide\n  Jeff Knupp post\n  Think Python\n  ","date":1626912000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1626912000,"objectID":"639fab6b12e2ca27bac5c46cfde40fe9","permalink":"https://fabiangunzinger.github.io/post/clean-code/","publishdate":"2021-07-22T00:00:00Z","relpermalink":"/post/clean-code/","section":"post","summary":" ","tags":["cs"],"title":"Clean code","type":"post"},{"authors":null,"categories":null,"content":"  ","date":1625270400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625270400,"objectID":"a28bc8df30f6e87e924d10e8dbe0aaf5","permalink":"https://fabiangunzinger.github.io/post/python-tricks/","publishdate":"2021-07-03T00:00:00Z","relpermalink":"/post/python-tricks/","section":"post","summary":"  ","tags":["python"],"title":"Python tricks","type":"post"},{"authors":null,"categories":null,"content":"Modules   A module is a file that contains definitions intended for reuse in a script or an interactive session.\n  Calling import module for the first time does three things: 1) create a new namespace that acts as the global namespace for all objects defined in module, 2) execute the entire module, 3) create a name – identical to the module name – within the caller namespace that references to the module. This can be used to access module objects in the caller namespace as module.object.\n  Calling from module import symbol imports symbol into the current namespace. However, the global namespace for symbol (if it’s a function) always remains the namespace in which it was defined, not the caller’s namespace.\n  Regardless of what variant of the import statement is being used to import contents from a module, all of the module’s statements will be initialised the first time (and only the first time) the module name is encountered in an import statement (more details here).\n  One reason from module import * is generally discouraged is that it directly imports all the module’s objects into the caller’s namespace, which is often said to cluter it up. Especially when importing large modules this makes sense, as it’s much cleaner to keep objects defined in imported modules in eponymous namespaces and accessing them via module.object, which immediately makes clear where object comes from and can help greatly with debugging.\n  One implication of all the above is that as a developer, you don’t have to worry about clashing variable names between modules, as they are each stored in their own namespace, and accessed via moduleA.foo and moduleB.foo in the caller namespace.\n  When we import a module foo, the interpreter first searches for a built-in module and, if none is found, searches a list of directories given the variable sys.path. sys.path contains the directory of the input script, the variable PYTHONPATH, and installation-dependent defaults. I can manipulate sys.path using standard list operations; to add a directory, use sys.path.append(\u0026#39;dirname\u0026#39;).\n  A common usecase of the above for me is to make a package available to Jupyter Notebooks. By default, a notebook’s sys.path contains the folder the noteook is located in and a bunch of conda managed directories linked to my running Conda environment. To make available a package that lives in the project root directory, just do sys.path.append(\u0026#39;/Users/fgu/dev/projectname/packagename\u0026#39;). I can then reference modules from the package using from packagename import module.\n  Use dir(modulename) to list all names defined in modulname, or dir() to list all names that are currently defined.\n  Running a module as a script   For relative imports to work as described, for instance, here and in Chapter 8 in Python Essential References and in recipees 10.1 and 10.3 in the Python Cookbook, the file into which you import has itself to be a module rather than a top-level script. If it’s the latter, it’s name will be main and it won’t be considered part of a package, regardless of where on the file system it is saved. Generally, for a file to be considered part of a package, it needs to nave a dot (.) in its name, as in package.submodule.modulename.\n  To import modules into a main script, one (somewhat unideal) solution is to add the absolute path to the package to sys.path.\n  Packages  Packages are collections of modules. They help structure Python’s module namespace by using dotted module names. E.g. a.b refers to submodule b in package a. Thus, just as the use of modules alleviates worries about clashing global variable names between modules, using a package alleviates worries about clashing module between multi-module packages.  Sources   Python docs - Modules\n  SO answer on relative imports for scripts\n  ","date":1621555200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621555200,"objectID":"20b138cbeb69e10625311e5e3d610f43","permalink":"https://fabiangunzinger.github.io/post/modules-and-packages/","publishdate":"2021-05-21T00:00:00Z","relpermalink":"/post/modules-and-packages/","section":"post","summary":" ","tags":["python"],"title":"Python modules and packages","type":"post"},{"authors":null,"categories":null,"content":"  ","date":1607904000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607904000,"objectID":"0a0a81467a4b618efe65cd4ec7c061b3","permalink":"https://fabiangunzinger.github.io/post/numpy-essentials/","publishdate":"2020-12-14T00:00:00Z","relpermalink":"/post/numpy-essentials/","section":"post","summary":"  ","tags":["python"],"title":"Numpy essentials","type":"post"},{"authors":null,"categories":null,"content":"Getting help and finding stuff  man \u0026lt;command\u0026gt; opens the manual for \u0026lt;command\u0026gt;. man -k \u0026lt;search term\u0026gt; lists all commands with \u0026lt;search term\u0026gt; in the manual pages. Search inside manual works as in vim.  Basics  A process is a running instance of a program. Everything is a fiele (the keyboard is read-only, the screen write only)  Misc. useful stuff I use often   ln -s [OPTIONS] FILE LINK. Create a soft link for FILE at LINK. If you use . for LINK, a link with the same name as FILE will be created in the current location.\n  In mac terminal, pbcopy and pbpaste allow you to copy from and paste to the terminal. I often use pwd | pbcopy to get a directory path for use elsewhere, and pbpaste \u0026gt; .gitignore to create a gitignore file from a template (e.g. from gitignore.io).\n  File handling  file lists file type of all files in a directory. wc returns the number of words, lines, and bytes of the input file. Options -w, -l, -c return any one of those counts, -m returns the number of characters. (Remember difference between wc -w \u0026lt;filename\u0026gt; and wc -w \u0026lt; \u0026lt;filename\u0026gt;: former prints file name, latter redirects file content to command anonymously, so prints result only.) cut print certain columns of input file. sed (stream edit) offers vim-like search and replace on data. uniq removes duplicates from data. egrep for regex-based filtering.  Processes  top to list most memory-intensive processes. ps lists processes running in current terminal, use -aux option to print all running processes (use | grep to filter output). kill [signal] \u0026lt;process id\u0026gt; to kill a process, use -9 signal to force if required. ctrl-z to move current job to background, jobs to list running background jobs, fg \u0026lt;job id\u0026gt; to move job to foreground.  Bash scripting Variables\n \u0026#39; interpret all content literally, \u0026#34; allow for variable substitution. $( command ) saves command output into a variable. export var makes var available to child process. /dev/stdin reads input from pipe.  Arithmetic\n let assigns result of expression to a variable. expr prints result of expression. $(( expression )) returns the result of expression. ${#var} returns the length of var in characters.  Functions\n function_name () { \u0026lt;commands\u0026gt; } is the basic format (there is also function function_name {, but I prefer this.  Permissions  Three actions: r (read), w (write), x (execute). Three types of users: owner or user (u), group (g), and others (o). (a) applies to all types. Permission info is 10 characters long: first character is file type (- for file, d for directory), the remaining ones are rwx permissions for owner, group, and others, with letter indicating permission on, hyphen indicating permission off. Changing persmission: chmod \u0026lt;user type\u0026gt;\u0026lt;add or remove\u0026gt;\u0026lt;permission type\u0026gt;. User type defaults to a. Example: chmod g+w adds write permission for group, chmod u-x removes execute permission for owner, chmod a+rwx grants all permission to everyone. chmod stands for change file mode bits. Shortcuts: Remember the following:     Octal Binary     0 000   1 001   2 010   3 011   4 100   5 101   6 110   7 111      This is useful because we can use the binary numbers to refer to rwx and the Octal ones as shortcuts (e.g. 5 is r-x). Further using the order of users as ugo, and using one Octal shortcut for each user, we can quickly set permissions for all users (e.g. 753 is rwxr-x-wx).\n  Directory permissions: r means you can read content (e.g. do ls), w means you can write (e.g. create files or subdirectories), and x means you can enter (e.g. cd).\n  Sources  Ryan’s bash-scripting tutorial Ryan’s linux tutorial  ","date":1605916800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605916800,"objectID":"b92856abe38b1e5c1173e9e1ee6fd82c","permalink":"https://fabiangunzinger.github.io/post/linux/","publishdate":"2020-11-21T00:00:00Z","relpermalink":"/post/linux/","section":"post","summary":" ","tags":["tools","cheatsheet"],"title":"Linux","type":"post"},{"authors":null,"categories":null,"content":"  ","date":1604361600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604361600,"objectID":"46da2ce357f0859d1c05618606fd3c04","permalink":"https://fabiangunzinger.github.io/post/idiomatic-python/","publishdate":"2020-11-03T00:00:00Z","relpermalink":"/post/idiomatic-python/","section":"post","summary":"  ","tags":["python"],"title":"Idiomatic Python","type":"post"},{"authors":null,"categories":null,"content":"  ","date":1601856000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601856000,"objectID":"5a92b24c81adf298cdf3032684dd70cd","permalink":"https://fabiangunzinger.github.io/post/python-functions/","publishdate":"2020-10-05T00:00:00Z","relpermalink":"/post/python-functions/","section":"post","summary":"  ","tags":["python"],"title":"Python functions","type":"post"},{"authors":null,"categories":null,"content":"  ","date":1601424000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601424000,"objectID":"4e1c951ad6d7d1e1f8b4ced4c84f0c8a","permalink":"https://fabiangunzinger.github.io/post/documenting-sample-selection/","publishdate":"2020-09-30T00:00:00Z","relpermalink":"/post/documenting-sample-selection/","section":"post","summary":"  ","tags":["datascience"],"title":"Documenting sample selection","type":"post"},{"authors":null,"categories":null,"content":"  ","date":1601424000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601424000,"objectID":"b7ab1b731872a295d15e042f7d9bae34","permalink":"https://fabiangunzinger.github.io/post/python-decorators/","publishdate":"2020-09-30T00:00:00Z","relpermalink":"/post/python-decorators/","section":"post","summary":"  ","tags":["python"],"title":"Python decorators","type":"post"},{"authors":null,"categories":null,"content":"  ","date":1596412800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596412800,"objectID":"73b2908d8f9ee53186167abb9f68b547","permalink":"https://fabiangunzinger.github.io/post/matplotlib/","publishdate":"2020-08-03T00:00:00Z","relpermalink":"/post/matplotlib/","section":"post","summary":"  ","tags":["dataviz"],"title":"Matplotlib","type":"post"},{"authors":null,"categories":null,"content":"  ","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585699200,"objectID":"6f79e28f7a052081272b8b4b99fb87b4","permalink":"https://fabiangunzinger.github.io/post/machine-learning-basics/","publishdate":"2020-04-01T00:00:00Z","relpermalink":"/post/machine-learning-basics/","section":"post","summary":"  ","tags":["stats"],"title":"Machine learning basics","type":"post"},{"authors":null,"categories":null,"content":"  ","date":1584835200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584835200,"objectID":"67c97026ded7b8d1b5b699dcb618a58e","permalink":"https://fabiangunzinger.github.io/post/python-built-in-heroes/","publishdate":"2020-03-22T00:00:00Z","relpermalink":"/post/python-built-in-heroes/","section":"post","summary":" ","tags":["python"],"title":"Python built-in heroes","type":"post"},{"authors":null,"categories":null,"content":"  ","date":1578960000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578960000,"objectID":"5588d9a0d6a53dae6698d911bb95c735","permalink":"https://fabiangunzinger.github.io/post/paradox/","publishdate":"2020-01-14T00:00:00Z","relpermalink":"/post/paradox/","section":"post","summary":"  ","tags":["datascience"],"title":"The waiting time paradox","type":"post"},{"authors":null,"categories":null,"content":"  ","date":1574467200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574467200,"objectID":"f301af679e4a076c5bac2ef37234f13f","permalink":"https://fabiangunzinger.github.io/post/naive-bayes/","publishdate":"2019-11-23T00:00:00Z","relpermalink":"/post/naive-bayes/","section":"post","summary":"  ","tags":["stats"],"title":"Naive Bayes","type":"post"},{"authors":null,"categories":null,"content":"My research page.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f1d044c0738ab9f19347f15c290a71a1","permalink":"https://fabiangunzinger.github.io/research/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/research/","section":"","summary":"My research page.","tags":null,"title":"Research","type":"widget_page"}]